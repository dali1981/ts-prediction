{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "def2842a",
      "metadata": {},
      "source": [
        "# Transformer Workflow Walkthrough\n",
        "\n",
        "This notebook demonstrates how to scaffold data ingestion, tokenization, and experiment configuration using the `transformers` toolkit. It builds a synthetic dataset, registers it in a catalog, and prepares both PatchTST and fusion model configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "466e4235",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(PosixPath('notebooks/_tmp/synthetic.csv'),\n",
              " PosixPath('notebooks/_tmp/brooks_vocab.json'))"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "from trading_transformers.data import DataCatalog, DataSource\n",
        "from trading_transformers.features import ContinuousFeatureBuilder, BrooksTokenizer\n",
        "from trading_transformers.tokenizers import BrooksTokenVocabulary\n",
        "\n",
        "TMP_ROOT = Path('notebooks/_tmp')\n",
        "TMP_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "CSV_PATH = TMP_ROOT / 'synthetic.csv'\n",
        "VOCAB_PATH = TMP_ROOT / 'brooks_vocab.json'\n",
        "\n",
        "# Synthetic OHLCV data\n",
        "synthetic = pd.DataFrame({\n",
        "    'timestamp': pd.date_range('2024-01-01', periods=400, freq='D'),\n",
        "    'open': 100 + pd.Series(range(400)).mul(0.05),\n",
        "    'high': 101 + pd.Series(range(400)).mul(0.05),\n",
        "    'low': 99 + pd.Series(range(400)).mul(0.05),\n",
        "    'close': 100 + pd.Series(range(400)).mul(0.05) + 0.3,\n",
        "    'volume': 1_000_000,\n",
        "})\n",
        "\n",
        "# Brooks-style tokens + vocabulary\n",
        "brooks = BrooksTokenizer()\n",
        "synthetic['brooks_token'] = brooks.transform(synthetic)\n",
        "vocab = BrooksTokenVocabulary.from_sequences(synthetic['brooks_token'])\n",
        "vocab.to_json(VOCAB_PATH)\n",
        "\n",
        "synthetic.to_csv(CSV_PATH, index=False)\n",
        "\n",
        "catalog = DataCatalog(root=TMP_ROOT)\n",
        "catalog.register_source(DataSource(name='synthetic', path=CSV_PATH, fmt='csv'))\n",
        "\n",
        "CSV_PATH, VOCAB_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e02e2d3c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>log_return</th>\n",
              "      <th>hl_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100.30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100.35</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.01994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100.40</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.01993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100.45</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.01992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100.50</td>\n",
              "      <td>0.000498</td>\n",
              "      <td>0.01991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    close  log_return  hl_range\n",
              "0  100.30         NaN       NaN\n",
              "1  100.35    0.000498   0.01994\n",
              "2  100.40    0.000498   0.01993\n",
              "3  100.45    0.000498   0.01992\n",
              "4  100.50    0.000498   0.01991"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Continuous feature inspection (optional)\n",
        "builder = ContinuousFeatureBuilder()\n",
        "features = builder.transform(synthetic)\n",
        "features[['close', 'log_return', 'hl_range']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "00023ac0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExperimentConfig(name='notebook_patchtst', data=DataConfig(source='synthetic', features=['open', 'high', 'low', 'close', 'volume'], target='close', lookback=64, horizon=8, batch_size=64, val_fraction=0.1, test_fraction=0.1, token_column=None, vocab_path=None), model={'type': 'patchtst', 'input_dim': 5}, optimizer=OptimizerConfig(lr=0.001, weight_decay=0.0001), trainer=TrainerConfig(max_epochs=5, accelerator='cpu', precision='32', gradient_clip_val=1.0, devices=None), output_dir=PosixPath('artifacts'))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from trading_transformers.training import DataConfig, ExperimentConfig, OptimizerConfig, TrainerConfig\n",
        "\n",
        "# PatchTST baseline configuration\n",
        "patch_data_cfg = DataConfig(\n",
        "    source='synthetic',\n",
        "    features=['open', 'high', 'low', 'close', 'volume'],\n",
        "    target='close',\n",
        "    lookback=64,\n",
        "    horizon=8,\n",
        "    batch_size=64,\n",
        ")\n",
        "patch_experiment = ExperimentConfig(\n",
        "    name='notebook_patchtst',\n",
        "    data=patch_data_cfg,\n",
        "    model={'type': 'patchtst', 'input_dim': 5},\n",
        "    optimizer=OptimizerConfig(lr=1e-3),\n",
        "    trainer=TrainerConfig(max_epochs=5, accelerator='cpu', precision='32'),\n",
        ")\n",
        "patch_experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "93a15194",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExperimentConfig(name='notebook_fusion', data=DataConfig(source='synthetic', features=['open', 'high', 'low', 'close', 'volume'], target='close', lookback=64, horizon=8, batch_size=64, val_fraction=0.1, test_fraction=0.1, token_column='brooks_token', vocab_path='notebooks/_tmp/brooks_vocab.json'), model={'type': 'fusion', 'd_model': 128, 'nheads': 4, 'depth': 2}, optimizer=OptimizerConfig(lr=0.001, weight_decay=0.0001), trainer=TrainerConfig(max_epochs=5, accelerator='cpu', precision='32', gradient_clip_val=1.0, devices=None), output_dir=PosixPath('artifacts'))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fusion configuration leveraging Brooks tokens\n",
        "fusion_data_cfg = DataConfig(\n",
        "    source='synthetic',\n",
        "    features=['open', 'high', 'low', 'close', 'volume'],\n",
        "    target='close',\n",
        "    lookback=64,\n",
        "    horizon=8,\n",
        "    batch_size=64,\n",
        "    token_column='brooks_token',\n",
        "    vocab_path=str(VOCAB_PATH),\n",
        ")\n",
        "fusion_experiment = ExperimentConfig(\n",
        "    name='notebook_fusion',\n",
        "    data=fusion_data_cfg,\n",
        "    model={\n",
        "        'type': 'fusion',\n",
        "        'd_model': 128,\n",
        "        'nheads': 4,\n",
        "        'depth': 2,\n",
        "    },\n",
        "    optimizer=OptimizerConfig(lr=1e-3),\n",
        "    trainer=TrainerConfig(max_epochs=5, accelerator='cpu', precision='32'),\n",
        ")\n",
        "fusion_experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc7d10c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Catalog saved to notebooks/_tmp/catalog.json\n",
            "Available archives (first five): ['SHARADAR_DAILY_3_1c00e922d0fc2ccdfae0e4c5271349a4', 'SHARADAR_SEP_2_0afbc06bfa7d2d5ebd28c43e0940ec30', 'SHARADAR_SF1_017f04a0d2ef7cc409f920be72167ada', 'SHARADAR_SF2_6ae86d850a382c2a8a24c5daa109c39b', 'SHARADAR_SF3_ce320d02f19d0b5d04c9557e0bc16680']\n"
          ]
        }
      ],
      "source": [
        "# Optionally auto-register real archives from ../data (SHARADAR bundles, etc.)\n",
        "from trading_transformers.data import auto_register_archives\n",
        "\n",
        "DATA_DIR = Path('../data')\n",
        "if DATA_DIR.exists():\n",
        "    auto_register_archives(catalog, DATA_DIR)\n",
        "    catalog_path = TMP_ROOT / 'catalog.json'\n",
        "    catalog.to_json(catalog_path)\n",
        "    print('Catalog saved to', catalog_path)\n",
        "    print('Available archives (first five):', catalog.list_archives()[:5])\n",
        "else:\n",
        "    print('No external data directory found; using synthetic catalog only.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "82576a00",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping extraction of SHARADAR_DAILY_3_1c00e922d0fc2ccdfae0e4c5271349a4 (607.1 MB)\n"
          ]
        }
      ],
      "source": [
        "if catalog.list_archives():\n",
        "    archive_name = catalog.list_archives()[0]\n",
        "    archive_path = Path(catalog.archives[archive_name].path)\n",
        "    size_mb = archive_path.stat().st_size / (1024 * 1024)\n",
        "    if size_mb < 250:\n",
        "        folder = catalog.extract_archive(archive_name)\n",
        "        print('Extracted to', folder)\n",
        "        sample_files = sorted(f.name for f in folder.glob('*'))[:5]\n",
        "        print('Sample files:', sample_files)\n",
        "    else:\n",
        "        print(f'Skipping extraction of {archive_name} ({size_mb:.1f} MB)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9b899c4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'token_stats': {'total_tokens': 400,\n",
              "  'unique_tokens': 1,\n",
              "  'entropy': -0.0,\n",
              "  'top_tokens': [('bull|bodyNA|tailNA|trend_up', 400)]},\n",
              " 'sample_tokens': ['bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up',\n",
              "  'bull|bodyNA|tailNA|trend_up'],\n",
              " 'vocab_size': 3}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Diagnostics for fusion tokens\n",
        "from trading_transformers.evaluation.diagnostics import fusion_token_report\n",
        "fusion_report = fusion_token_report(synthetic, fusion_data_cfg)\n",
        "fusion_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d5313005",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/mohamedali/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
            "/Users/mohamedali/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "\n",
            "  | Name     | Type           | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | backbone | FusionBackbone | 406 K  | train\n",
            "1 | head     | Linear         | 1.0 K  | train\n",
            "----------------------------------------------------\n",
            "407 K     Trainable params\n",
            "0         Non-trainable params\n",
            "407 K     Total params\n",
            "1.628     Total estimated model params size (MB)\n",
            "28        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af04c54845524bab8933873bc4293ef6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |                                                                                | 0/? [00:00\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mohamedali/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
            "/Users/mohamedali/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
            "/Users/mohamedali/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbef076bc8044f81925da1ce38bbb919",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |                                                                                       | 0/? [00:00\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51651a25430643378f89ad773a671bb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                                     | 0/? [00:00\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db3c1ed043ab48f19c620e39ec742958",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                                     | 0/? [00:00\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ca747432e74486db1e17e44f6aca8e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                                     | 0/? [00:00\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "185118db6f3740d38ecf7fdaa687a6af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                                     | 0/? [00:00\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "348428405e4e45ac8c61667eef6a0c45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |                                                                                     | 0/? [00:00\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "/Users/mohamedali/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:149: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
            "Restoring states from the checkpoint path at artifacts/lightning_logs/version_1/checkpoints/epoch=4-step=25.ckpt\n",
            "Loaded model weights from the checkpoint at artifacts/lightning_logs/version_1/checkpoints/epoch=4-step=25.ckpt\n"
          ]
        },
        {
          "ename": "MisconfigurationException",
          "evalue": "`test_dataloader` must be implemented to be used with the Lightning Trainer",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMisconfigurationException\u001b[39m                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m runner = ExperimentRunner(config=fusion_experiment, catalog=catalog)\n\u001b[32m      5\u001b[39m trainer = runner.run()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDiagnostics from runner:\u001b[39m\u001b[33m'\u001b[39m, runner.report)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:774\u001b[39m, in \u001b[36mTrainer.test\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    773\u001b[39m \u001b[38;5;28mself\u001b[39m.testing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:816\u001b[39m, in \u001b[36mTrainer._test_impl\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    812\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    813\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    814\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    815\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[32m    818\u001b[39m results = convert_tensors_to_scalars(results)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1011\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1016\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1048\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28mself\u001b[39m.lightning_module.zero_grad()\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluating:\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predicting:\n\u001b[32m   1050\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict_loop.run()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     context_manager = torch.no_grad\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py:120\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;129m@_no_grad_context\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[_OUT_DICT]:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip:\n\u001b[32m    122\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/evaluation_loop.py:176\u001b[39m, in \u001b[36m_EvaluationLoop.setup_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    174\u001b[39m stage = \u001b[38;5;28mself\u001b[39m._stage\n\u001b[32m    175\u001b[39m source = \u001b[38;5;28mself\u001b[39m._data_source\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m dataloaders = \u001b[43m_request_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m trainer.strategy.barrier(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage.dataloader_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_dataloader()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataloaders, CombinedLoader):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:334\u001b[39m, in \u001b[36m_request_dataloader\u001b[39m\u001b[34m(data_source)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\u001b[39;00m\n\u001b[32m    324\u001b[39m \n\u001b[32m    325\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[33;03m    The requested dataloader\u001b[39;00m\n\u001b[32m    327\u001b[39m \n\u001b[32m    328\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _replace_dunder_methods(DataLoader, \u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m), _replace_dunder_methods(BatchSampler):\n\u001b[32m    330\u001b[39m     \u001b[38;5;66;03m# under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as\u001b[39;00m\n\u001b[32m    331\u001b[39m     \u001b[38;5;66;03m# attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning.\u001b[39;00m\n\u001b[32m    332\u001b[39m     \u001b[38;5;66;03m# Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__`\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# methods so that the re-instantiated object is as close to the original as possible.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata_source\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:298\u001b[39m, in \u001b[36m_DataLoaderSource.dataloader\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the dataloader from the source.\u001b[39;00m\n\u001b[32m    293\u001b[39m \n\u001b[32m    294\u001b[39m \u001b[33;03mIf the source is a module, the method with the corresponding :attr:`name` gets called.\u001b[39;00m\n\u001b[32m    295\u001b[39m \n\u001b[32m    296\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.instance, pl.LightningModule):\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.instance, pl.LightningDataModule):\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.instance.trainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:177\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m pl_module._current_fx_name = hook_name\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    180\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/trading_project/models/.venv/lib/python3.13/site-packages/pytorch_lightning/core/hooks.py:512\u001b[39m, in \u001b[36mDataHooks.test_dataloader\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> EVAL_DATALOADERS:\n\u001b[32m    485\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"An iterable or collection of iterables specifying test samples.\u001b[39;00m\n\u001b[32m    486\u001b[39m \n\u001b[32m    487\u001b[39m \u001b[33;03m    For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m \n\u001b[32m    511\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[33m\"\u001b[39m\u001b[33m`test_dataloader` must be implemented to be used with the Lightning Trainer\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mMisconfigurationException\u001b[39m: `test_dataloader` must be implemented to be used with the Lightning Trainer"
          ]
        }
      ],
      "source": [
        "# Training requires PyTorch Lightning and torch.\n",
        "# Uncomment once dependencies are installed.\n",
        "# from trading_transformers.training import ExperimentRunner\n",
        "# runner = ExperimentRunner(config=fusion_experiment, catalog=catalog)\n",
        "# trainer = runner.run()\n",
        "# if runner.report.get('token_stats', {}).get('total_tokens', 0) > 0:\n",
        "#     print('Diagnostics from runner:', runner.report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01b105a",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "- Swap the synthetic dataset with your catalog source and rerun diagnostics (`fusion_token_report`).\n",
        "- Use the CLI: `python -m trading_trading_transformers.training --config transformers/configs/fusion.yaml --catalog notebooks/_tmp/catalog.json --diagnostics fusion_report.json`.\n",
        "- Feed model forecasts into `python -m trading_trading_transformers.backtest` for P&L assessment.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}