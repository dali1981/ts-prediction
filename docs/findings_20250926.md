# Data Pipeline Findings — 2025-09-26

This memo captures the three critical issues observed during the review of the data ingestion and preparation stack. Each section describes the problem, why it matters, and how it can surface in practice.

## 1. Token Windows Drift After `dropna`

**Where:** `trading_transformers/training/datamodule.py:68-81`

**What happens:**
- Continuous features and the target column are stacked after calling `frame[features + [target]].dropna()`.
- Token indices (if configured) are truncated from the *end* of the original array via `tokens_array = tokens_array[-len(values):]`.
- If NaNs appear in the middle of the frame, the NaN rows are removed from the continuous/target matrix but remain in their original positions inside the token array before the truncation runs.
- The trailing slice therefore realigns the token windows with the **wrong episodes**.

**Example:**
```text
idx : feature window (dropna)         token column (original)
----+-------------------------------+---------------------------------
  0 | valid                         | bull
  1 | NaN → removed                 | bear
  2 | valid                         | doji
  3 | valid                         | bull
```
After `dropna()`, the feature rows `[0, 2, 3]` remain. The token array still contains `[bull, bear, doji, bull]` and the truncation keeps the last three tokens: `[bear, doji, bull]`. The window that should align with index 2 now receives `bear`, shifting all subsequent windows by one step.

**Impact:** Fusion experiments that rely on token supervision can learn the wrong context or fail due to label leakage.

## 2. Token Column Must Already Be Numeric

**Where:** `trading_transformers/training/datamodule.py:48-51`

**What happens:**
- `_encode_tokens` falls back to `series.to_numpy(dtype=np.int64)` whenever no vocabulary file is supplied.
- Most pre-tokenised CSV exports keep the token column as strings (e.g., `"bull_trend"`). Pandas cannot coerce those strings into `int64` and raises a `TypeError`.

**Example session:**
```python
window = WindowGenerator(config_with_token_column_but_no_vocab)
window.generate(frame)
# → TypeError: Cannot cast array data from dtype('<U10') to dtype('int64') according to the rule 'safe'
```

**Impact:** Token-aware configs silently break unless the user pre-encodes tokens to integers. The behaviour is surprising, because providing `token_column` implies the generator will handle encoding.

## 3. Catalog Paths Are Not Portable

**Where:** `trading_transformers/data/catalog.py:133-140`

**What happens:**
- Catalog entries are serialised with whatever `path` string is registered (`catalog.to_json`).
- `DataCatalog.from_json` reconstructs each `DataSource` by calling `Path(src["path"])` without referencing `catalog.root`.
- If the JSON contains relative paths and the caller loads the catalog from a different working directory, `Path` resolves relative to the *current* working directory rather than the catalog root.

**Example:**
1. Create catalog while `cwd=/home/user/project` with `path="data/eth.csv"`.
2. Later run training from `/home/user/project/scripts`. The loader now looks for `scripts/data/eth.csv`, which does not exist.

**Impact:** Catalogs become brittle once they are shared, checked into git, or consumed from execution environments with different working directories.

---

Addressing these issues will stabilise the shared data interface across fusion experiments and alternative model stacks.
